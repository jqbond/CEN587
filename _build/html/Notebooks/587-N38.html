
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Useful Ancillary Skills for Regression &#8212; Kinetics and Reaction Engineering</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Notebooks/587-N38';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Interpolation and Regression" href="587-N37.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/JQB.png" class="logo__image only-light" alt="Kinetics and Reaction Engineering - Home"/>
    <script>document.write(`<img src="../_static/JQB.png" class="logo__image only-dark" alt="Kinetics and Reaction Engineering - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Welcome to CEN 587!
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../Chapter2.html">Lectures</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="587-N37.html">Interpolation and Regression</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Useful Ancillary Skills for Regression</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/jqbond/CEN587/main?urlpath=tree/Notebooks/587-N38.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/jqbond/CEN587" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/jqbond/CEN587/issues/new?title=Issue%20on%20page%20%2FNotebooks/587-N38.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Notebooks/587-N38.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Useful Ancillary Skills for Regression</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-recap">A Recap</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ancillary-skills">Ancillary Skills</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#python-will-do-all-this-stuff-for-you-if-you-want">Python will do all this stuff for you if you want…</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="useful-ancillary-skills-for-regression">
<h1>Useful Ancillary Skills for Regression<a class="headerlink" href="#useful-ancillary-skills-for-regression" title="Link to this heading">#</a></h1>
<p>In <a class="reference external" href="https://jqbond.github.io/CEN587/Notebooks/587-N37.html">Notebook 37</a>, we covered the fundamental, mathematical basis for constructing interpolating polynomials and regression polynomials. Both of these tools can be used to model trends in data. They are especially valuable to us because they allow us to use measurements and observations to generate a continuous function that describes the relationship between an input (independent) variable and an output (observable or measured variable). Once we have this function, we can use it to make predictions about the value that an observable will take on at values of the input variable that we did not measure. Here, we summararize a few ancillary statistical tools that are often used alongside regression analysis to quantify goodness of fit and allow us to compare different models. Now that we understand the mathematics of the approach, we will also introduce Python functions that automate some of the regression process, similar to what Trendline or LINEST would do in Excel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">opt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">math</span><span class="w"> </span><span class="kn">import</span> <span class="n">ceil</span><span class="p">,</span> <span class="n">floor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</pre></div>
</div>
</div>
</div>
<section id="a-recap">
<h2>A Recap<a class="headerlink" href="#a-recap" title="Link to this heading">#</a></h2>
<p>Let’s start by recalling the 11 <span class="math notranslate nohighlight">\((x,y)\)</span> pairs from <a class="reference external" href="https://jqbond.github.io/CEN587/Notebooks/587-N37.html">Notebook 37</a>. We will use the same seed for our random number generator here, which will generate the same set of “random” <span class="math notranslate nohighlight">\((x,y)\)</span> pairs as before. We do this here to ensure that we get the same regression results in the two notebooks, and also that we get the same regression results each time we run the Notebook.  If we did not set the RNG seed, we would get a different data set each time the Notebook kernel is restarted, which makes it difficult to consistently discuss the observed trends.</p>
<p>In the cell below, we’ll generate the data and fit a first order model to it, and overlay the results graphically as we did in the previous Notebooks. Subsequently, we’ll establish a systematic way for reporting the results of linear regression analysis. This will allow us to quickly assess “goodness of fit” and to compare the quality of fit for various models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#########################################################################################################################</span>
<span class="c1"># set the seed for randon number generation; this ensures we get the same &quot;random&quot; number set each time we run the cell #</span>
<span class="c1">#########################################################################################################################</span>
 
<span class="n">rng</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">12345</span><span class="p">)</span>

<span class="c1">#########################################################################################################################</span>
<span class="c1"># Generate 11 random x values and 11 random y values; print the results to screen                                       #</span>
<span class="c1">#########################################################################################################################</span>

<span class="n">xdata</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span>
<span class="n">ydata</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ydata</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Generate Y array of observables/measured quantities                                #</span>
<span class="c1">######################################################################################</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">ydata</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Generate truncated vandermonde matrix @ second order                               #</span>
<span class="c1"># This has 4 columns, x^3, x^2, x^1, x^0                                             #</span>
<span class="c1">######################################################################################</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vander</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Solve for optimum set of coefficients for the 2nd order model, display results     #</span>
<span class="c1">######################################################################################</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="nd">@X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="nd">@Y</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

<span class="c1">#################################################################################</span>
<span class="c1"># Define large array of x values for generating smooth continuous line plot     #</span>
<span class="c1">#################################################################################</span>

<span class="n">xline</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Define lambda function for best fit 2nd order model using regressed coefficients   #</span>
<span class="c1">######################################################################################</span>

<span class="n">yline</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Overlay measured y data, predicted y data, and continuous 2nd order function y(x)  #</span>
<span class="c1">######################################################################################</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;measured data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span> <span class="n">yline</span><span class="p">(</span><span class="n">xline</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;regressed y(x)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">X</span><span class="nd">@A</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;data predictions&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.22733602 0.31675834 0.79736546 0.67625467 0.39110955 0.33281393
 0.59830875 0.18673419 0.67275604 0.94180287 0.24824571] 

[0.94888115 0.66723745 0.09589794 0.44183967 0.88647992 0.6974535
 0.32647286 0.73392816 0.22013496 0.08159457 0.1598956 ] 

[-0.90421001  0.92118569]
</pre></div>
</div>
<img alt="../_images/9691ee14e928e094b52e9986cba7293da053a333cb5d8337110b72bc99354a37.png" src="../_images/9691ee14e928e094b52e9986cba7293da053a333cb5d8337110b72bc99354a37.png" />
</div>
</div>
<section id="ancillary-skills">
<h3>Ancillary Skills<a class="headerlink" href="#ancillary-skills" title="Link to this heading">#</a></h3>
<p>Whenver we perform least squares regression, we are minimizing the residual sum of squares. This quantity is defined as:</p>
<div class="math notranslate nohighlight">
\[SSE = \sum_i (y_i - \hat{y}_i)^2\]</div>
<p>It can be calculated using a summation, which is relatively straighforward in Python using <code class="docutils literal notranslate"><span class="pre">numpy.sum()</span></code> and operating on arrays of data. Alternatively, when solving linear regression problems using <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(A\)</span> matrices/arrays, we can calculate the residual sum of squares using the following matrix formula:</p>
<div class="math notranslate nohighlight">
\[SSE = (Y - XA)^T(Y - XA)\]</div>
<p>In <code class="docutils literal notranslate"><span class="pre">numpy</span></code> the above expression would be written using the <code class="docutils literal notranslate"><span class="pre">&#64;</span></code> and <code class="docutils literal notranslate"><span class="pre">.T</span></code> operators as:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>SSE = (Y - X@A).T@(Y - X@A)
</pre></div>
</div>
<p>It may not look like it at first, but if you write out the matrix product, you should see that you generate the exact same right hand side as the form using a summation operator. One thing that we should be mindful of is that the residual sum of squares is a function of the number of data points in our system and the size of the measurements that we are working with. For example, if we work with a data set comprised of 1000 <span class="math notranslate nohighlight">\((x,y)\)</span> pairs, it will usually have a larger residual sum of squares than a data set comprised of 10 <span class="math notranslate nohighlight">\((x,y)\)</span> pairs. In addition, if our measured values of <span class="math notranslate nohighlight">\(y\)</span> are on the order of 1000, we will generally observe a larger absolute residual sum of squares than if our measured values of <span class="math notranslate nohighlight">\(y\)</span> are on the order of <span class="math notranslate nohighlight">\(10^{-3}\)</span>. Because of these issues, the absolute magnitude of residual sum of squares is not an especially meaningful way to quantify the error in a given fit or optimization, and we frequently look at other metrics to quantify goodness of fit. For example, the Mean Square Error (MSE) is useful because it normalizes residual sum of squares by the number of measurements; as such, it represents the <em><strong>average square error</strong></em> in our data fit, which can be used to assess models fit to data sets of different size:</p>
<div class="math notranslate nohighlight">
\[MSE = \frac{SSE}{n_m}\]</div>
<p>In this expression, <span class="math notranslate nohighlight">\(n_m\)</span> is the number of data points/measurements. We can use the MSE to then generate the root mean square error (RMSE), which is a good approximation of the absolute value of the displacement (error) between our model and our measurement.</p>
<div class="math notranslate nohighlight">
\[RMSE = \sqrt{MSE}\]</div>
<p>The total sum of squares is used to quantify the error between the measurement and the mean of measurments. Basically, this is the residual sum of squares that results if we assume that our model is that <span class="math notranslate nohighlight">\(y = \bar{y}\)</span> for any value of <span class="math notranslate nohighlight">\(x\)</span>:</p>
<div class="math notranslate nohighlight">
\[SST = \sum_i (y_i - \bar{y}_i)\]</div>
<p>We can use the residual sum of squares and the total sum of squares to can calculate the coefficient of determination (the beloved <span class="math notranslate nohighlight">\(R^2\)</span>):</p>
<div class="math notranslate nohighlight">
\[R^2 = 1 - \frac{SSE}{SST}\]</div>
<p>It is generally also useful to quantify the level of uncertainty in the parameters (e.g., coefficients) that we estimate using regression analysis. For linear regression, there is a well-defined procedure for doing so. First, we need to know the variance for the regressed model, <span class="math notranslate nohighlight">\(\sigma^2\)</span>. This is generally unknown, but we assume that it can be approximated:</p>
<div class="math notranslate nohighlight">
\[\sigma^2 \approx s^2\]</div>
<p>This is convenient because <span class="math notranslate nohighlight">\(s^2\)</span> can be calculated from our data:</p>
<div class="math notranslate nohighlight">
\[s^2 = \frac{SSE}{n_m - n_p}\]</div>
<p>Here <span class="math notranslate nohighlight">\(n_m\)</span> is the number of measurements and <span class="math notranslate nohighlight">\(n_p\)</span> is the number of regressed parameters. The difference between these two, <span class="math notranslate nohighlight">\(n_m - n_p\)</span> is also known as the “degrees of freedom” in our regression.</p>
<div class="math notranslate nohighlight">
\[s^2 = \frac{SSE}{DOF}\]</div>
<p>With <span class="math notranslate nohighlight">\(s^2\)</span> calculated, we can estimate the covariance matrix:</p>
<div class="math notranslate nohighlight">
\[COV = s^2(X^TX)^{-1}\]</div>
<p>The standard error in our regressed parameters is given by the diagonal elements in the following matrix:</p>
<div class="math notranslate nohighlight">
\[se = \sqrt{COV}\]</div>
<p>Noting that this may throw a warning if off-diagonal elements of the covariance matrix are negative.</p>
<p>From that, we get the standard error in the slope from <code class="docutils literal notranslate"><span class="pre">se[0,0]</span></code> and the standard error in the intercept from <code class="docutils literal notranslate"><span class="pre">se[1,1]</span></code>, i.e., the diagonal elements.</p>
<p>One can then use these quantities with relevant values from the <a class="reference external" href="https://en.wikipedia.org/wiki/Student%27s_t-distribution">Student’s t-distribution</a> to calculate confidence intervals, they are given by:</p>
<div class="math notranslate nohighlight">
\[CI = t(q, DOF)\times SE\]</div>
<p>In this formula, the value of the t-distribution is obtained at a specified confidence level <span class="math notranslate nohighlight">\(q\)</span> and for the number of degrees of freedom in the regression. Finally, it is convenient to remember that, because we are working with a linear system defined in terms of matrices, we can, predict values of the observable, measured quantityby multiplying the Vandermonde matrix by the array of regressed coefficients:</p>
<div class="math notranslate nohighlight">
\[\hat{Y} = X\hat{A}\]</div>
<p>The formulae given above are all embedded along with the least squares calculation in the cell below; this block will be used as a standard component of linear regression analysis for the remainder of the course.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The calculations below are general and can be applied to any linear regression once the <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> arrays are defined!</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#####################################################################################################</span>
<span class="c1"># Define the X matrix and Y array                                                                   #</span>
<span class="c1">#####################################################################################################</span>

<span class="n">Y</span>     <span class="o">=</span> <span class="n">ydata</span>
<span class="n">X</span>     <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vander</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c1">#This creates the X matrix shown above, truncating at 1st order</span>

<span class="c1">#####################################################################################################</span>
<span class="c1"># Solve the least squares problem to find the best fit coefficients                                 #</span>
<span class="c1">#####################################################################################################</span>

<span class="n">A</span>      <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="nd">@X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="nd">@Y</span><span class="p">)</span> 

<span class="c1">#####################################################################################################</span>
<span class="c1"># Workup and analysis for quantifying and visualizing goodness of fit                               #</span>
<span class="c1">#####################################################################################################</span>

<span class="n">Ypred</span>  <span class="o">=</span> <span class="n">X</span><span class="nd">@A</span>                          <span class="c1">#Calculate discrete array of predicted y values at each x value</span>
<span class="n">Ybar</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ydata</span><span class="p">)</span>               <span class="c1">#Calculate the mean of the measured y values, use for SST calculation</span>
<span class="n">Ndata</span>  <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ydata</span><span class="p">)</span>                   <span class="c1">#Calculate the number of data points/measurementws</span>
<span class="n">SSE1</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">Y</span> <span class="o">-</span> <span class="n">Ypred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>       <span class="c1">#Calculate residual sum of squares using intuitive summation formula</span>
<span class="n">SSE2</span>   <span class="o">=</span> <span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">X</span><span class="nd">@A</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">@</span><span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">X</span><span class="nd">@A</span><span class="p">)</span>        <span class="c1">#Calculate residual sum of squares using matrix multiplication; equivalent to SSE1</span>
<span class="n">SST</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">Y</span> <span class="o">-</span> <span class="n">Ybar</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>       <span class="c1">#Calculate total sum of squares; assumes model is just y_pred = mean(ydata)</span>
<span class="n">MSE</span>    <span class="o">=</span> <span class="n">SSE1</span><span class="o">/</span><span class="n">Ndata</span>                   <span class="c1">#Calculate mean square error</span>
<span class="n">RMSE</span>   <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">MSE</span><span class="p">)</span>                 <span class="c1">#Calculate root mean square error</span>
<span class="n">R2</span>     <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">SSE1</span><span class="o">/</span><span class="n">SST</span>                 <span class="c1">#Calculate R2 (coefficient of determination)</span>
<span class="n">DOF</span>    <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ydata</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>          <span class="c1">#Count degrees of freedom</span>
<span class="n">s2</span>     <span class="o">=</span> <span class="n">SSE1</span><span class="o">/</span><span class="n">DOF</span>                     <span class="c1">#Estimate variance</span>
<span class="n">COV</span>    <span class="o">=</span> <span class="n">s2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="nd">@X</span><span class="p">)</span>      <span class="c1">#Generate the covariance matrix for this fit</span>
<span class="n">m</span>      <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>                         <span class="c1">#This is a linear model; with the way we define the X matrix, slope is A[0], intercept is A[1]</span>
<span class="n">b</span>      <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>                         <span class="c1">#This is a linear model; with the way we define the X matrix, slope is A[0], intercept is A[1] </span>
<span class="n">SEm</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">COV</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>           <span class="c1">#For our definition of the X matrix, standard error in the slope is the first diagonal element in COV</span>
<span class="n">SEb</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">COV</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>           <span class="c1">#For our definition of the X matrix, standard error in the intercept is the second diagonal element in COV</span>
<span class="n">tval</span>   <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.975</span><span class="p">,</span> <span class="n">DOF</span><span class="p">)</span>      <span class="c1">#t distribution for 95% confidence interval t(1 - α/2, DOF), α = 0.05 for 95% confidence interval</span>
<span class="n">CIm</span>    <span class="o">=</span> <span class="n">SEm</span><span class="o">*</span><span class="n">tval</span>                     <span class="c1">#confidence interval on slope</span>
<span class="n">CIb</span>    <span class="o">=</span> <span class="n">SEb</span><span class="o">*</span><span class="n">tval</span>                     <span class="c1">#confidence interval on intercept</span>

<span class="c1">############################################################################################</span>
<span class="c1"># Printing results using f strings; create arrays of labels and values                     #</span>
<span class="c1">############################################################################################</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;SSE&#39;</span><span class="p">,</span> <span class="s1">&#39;SST&#39;</span><span class="p">,</span><span class="s1">&#39;MSE&#39;</span><span class="p">,</span><span class="s1">&#39;RMSE&#39;</span><span class="p">,</span> <span class="s1">&#39;R2&#39;</span><span class="p">]</span>
<span class="n">values</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span>  <span class="p">,</span>  <span class="n">b</span> <span class="p">,</span>  <span class="n">SSE1</span><span class="p">,</span>  <span class="n">SST</span> <span class="p">,</span> <span class="n">MSE</span> <span class="p">,</span> <span class="n">RMSE</span><span class="p">,</span>  <span class="n">R2</span><span class="p">]</span>

<span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="s1">&#39;m&#39;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">label</span><span class="si">:</span><span class="s1">4s</span><span class="si">}</span><span class="s1"> = </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1"> +/- </span><span class="si">{</span><span class="n">CIm</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">label</span> <span class="o">==</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">label</span><span class="si">:</span><span class="s1">4s</span><span class="si">}</span><span class="s1"> = </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1"> +/- </span><span class="si">{</span><span class="n">CIm</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">label</span><span class="si">:</span><span class="s1">4s</span><span class="si">}</span><span class="s1"> = </span><span class="si">{</span><span class="n">value</span><span class="si">:</span><span class="s1">0.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>


<span class="c1">############################################################################################</span>
<span class="c1"># Visualizing results; overlay data, predictions, and continuous regressed y(x)            #</span>
<span class="c1">############################################################################################</span>

<span class="n">xline</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">yline</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">A</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;measured data&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span> <span class="n">yline</span><span class="p">(</span><span class="n">xline</span><span class="p">),</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;smoothed regression line&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">X</span><span class="nd">@A</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;data predictions&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>m    = -0.90 +/- 0.65
b    = 0.92 +/- 0.65
SSE  = 0.49
SST  = 1.03
MSE  = 0.04
RMSE = 0.21
R2   = 0.52
</pre></div>
</div>
<img alt="../_images/1801b93ba860bd853d690d8890728925a23fedf2ae6152958a7546ce0cc22cec.png" src="../_images/1801b93ba860bd853d690d8890728925a23fedf2ae6152958a7546ce0cc22cec.png" />
</div>
</div>
</section>
</section>
<section id="python-will-do-all-this-stuff-for-you-if-you-want">
<h2>Python will do all this stuff for you if you want…<a class="headerlink" href="#python-will-do-all-this-stuff-for-you-if-you-want" title="Link to this heading">#</a></h2>
<p>For your reference, Python includes most of the above calculations in its various options for automatically through either <code class="docutils literal notranslate"><span class="pre">numpy.polyfit()</span></code> or <code class="docutils literal notranslate"><span class="pre">numpy.linalg.leastsq()</span></code>.  The cell below shows the use of <code class="docutils literal notranslate"><span class="pre">numpy.polyfit()</span></code> to fit first, second, and third order polynomials to the data.  You can see that this requires much less work on our part; the trade off is that the calculations are not transparent to us, so lose a bit of insight about how linear regression actually works. Regardless, we get the same coefficients as we did in <a class="reference external" href="https://jqbond.github.io/CEN587/Notebooks/587-N37.html">Notebook 37</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#####################################################################################################</span>
<span class="c1"># First order regression using matrix methods                                                       #</span>
<span class="c1">#####################################################################################################</span>

<span class="n">Y1</span> <span class="o">=</span> <span class="n">ydata</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vander</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="c1">#This creates the X matrix shown above, truncating at 1st order</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">T</span><span class="nd">@X1</span><span class="p">,</span> <span class="n">X1</span><span class="o">.</span><span class="n">T</span><span class="nd">@Y1</span><span class="p">)</span> 

<span class="c1">#####################################################################################################</span>
<span class="c1"># First order regression using numpy.polyfit()                                                      #</span>
<span class="c1">#####################################################################################################</span>

<span class="n">A1np_poly</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1">#####################################################################################################</span>
<span class="c1"># Second order regression using matrix methods                                                      #</span>
<span class="c1">#####################################################################################################</span>

<span class="n">Y2</span> <span class="o">=</span> <span class="n">ydata</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vander</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="c1">#This creates the X matrix shown above, truncating at 1st order</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X2</span><span class="o">.</span><span class="n">T</span><span class="nd">@X2</span><span class="p">,</span> <span class="n">X2</span><span class="o">.</span><span class="n">T</span><span class="nd">@Y2</span><span class="p">)</span>

<span class="c1">#####################################################################################################</span>
<span class="c1"># Second order regression using numpy.polyfit()                                                     #</span>
<span class="c1">#####################################################################################################</span>

<span class="n">A2np_poly</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1">#####################################################################################################</span>
<span class="c1"># Third order regression using matrix methods                                                      #</span>
<span class="c1">#####################################################################################################</span>

<span class="n">Y3</span> <span class="o">=</span> <span class="n">ydata</span>
<span class="n">X3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vander</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="c1">#This creates the X matrix shown above, truncating at 1st order</span>
<span class="n">A3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X3</span><span class="o">.</span><span class="n">T</span><span class="nd">@X3</span><span class="p">,</span> <span class="n">X3</span><span class="o">.</span><span class="n">T</span><span class="nd">@Y3</span><span class="p">)</span>

<span class="c1">#####################################################################################################</span>
<span class="c1"># Third order regression using numpy.polyfit()                                                      #</span>
<span class="c1">#####################################################################################################</span>

<span class="n">A3np_poly</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1">#Fit a third order polynomial to data, four coefficients</span>

<span class="c1">#####################################################################################################</span>
<span class="c1"># Compare coefficients obtained using matrix methods vs. numpy.polyfit()                            #</span>
<span class="c1">#####################################################################################################</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">A1</span><span class="p">,</span> <span class="n">A1np_poly</span><span class="p">]),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">A2</span><span class="p">,</span> <span class="n">A2np_poly</span><span class="p">]),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">A3</span><span class="p">,</span> <span class="n">A3np_poly</span><span class="p">]),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[-0.90421001  0.92118569]
 [-0.90421001  0.92118569]] 

[[-0.69969354 -0.14991027  0.76170812]
 [-0.69969354 -0.14991027  0.76170812]] 

[[ 4.85887321 -9.04727267  4.12600401  0.14299066]
 [ 4.85887321 -9.04727267  4.12600401  0.14299066]] 
</pre></div>
</div>
</div>
</div>
<p>Regression tools in <code class="docutils literal notranslate"><span class="pre">numpy</span></code> are very nice because in addition to performing the regression (using <code class="docutils literal notranslate"><span class="pre">np.polyfit()</span></code>), they will also automate construction of the regressed polynomial function using <code class="docutils literal notranslate"><span class="pre">np.polyval()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">######################################################################################</span>
<span class="c1"># Evaluate the best fit first order model at all 100 values in xline                 #</span>
<span class="c1">######################################################################################</span>

<span class="n">first</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyval</span><span class="p">(</span><span class="n">A1np_poly</span><span class="p">,</span> <span class="n">xline</span><span class="p">)</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Evaluate the best fit second order model at all 100 values in xline                #</span>
<span class="c1">######################################################################################</span>

<span class="n">second</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyval</span><span class="p">(</span><span class="n">A2np_poly</span><span class="p">,</span> <span class="n">xline</span><span class="p">)</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Evaluate the best fit third order model at all 100 values in xline                 #</span>
<span class="c1">######################################################################################</span>

<span class="n">third</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyval</span><span class="p">(</span><span class="n">A3np_poly</span><span class="p">,</span> <span class="n">xline</span><span class="p">)</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Overlay observed data and the regressed y(x) result for first order model          #</span>
<span class="c1">######################################################################################</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span> <span class="n">first</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;regressed first order&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Overlay observed data and the regressed y(x) result for second order model         #</span>
<span class="c1">######################################################################################</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span> <span class="n">second</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;regressed second order&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1">######################################################################################</span>
<span class="c1"># Overlay observed data and the regressed y(x) result for third order model          #</span>
<span class="c1">######################################################################################</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xdata</span><span class="p">,</span> <span class="n">ydata</span><span class="p">,</span> <span class="n">marker</span> <span class="o">=</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">edgecolor</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xline</span><span class="p">,</span> <span class="n">third</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;regressed third order&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/cda0a20cb234d09ce1417419e25bfe30294c0216a9d34308368ab410faf3f34a.png" src="../_images/cda0a20cb234d09ce1417419e25bfe30294c0216a9d34308368ab410faf3f34a.png" />
<img alt="../_images/5e745846746e6f67a8ec7c1d7d5d09d3054279e6443d1a07f3a7ac95e4a0cb13.png" src="../_images/5e745846746e6f67a8ec7c1d7d5d09d3054279e6443d1a07f3a7ac95e4a0cb13.png" />
<img alt="../_images/73f3739085f84fa4c4c6e64015891eadeb41515c0cc02c27a2897239759badd5.png" src="../_images/73f3739085f84fa4c4c6e64015891eadeb41515c0cc02c27a2897239759badd5.png" />
</div>
</div>
<p>It is also worth mentioning that <code class="docutils literal notranslate"><span class="pre">numpy</span></code> has a built in least squares version of <code class="docutils literal notranslate"><span class="pre">np.linalg.solve()</span></code>, which has a very similar syntax to  <code class="docutils literal notranslate"><span class="pre">np.linalg.solve()</span></code> in that it operates directly on the <span class="math notranslate nohighlight">\(X\)</span> matrix and <span class="math notranslate nohighlight">\(Y\)</span> array – no need for transposes – but it returns least squares regressed coefficients. See results below for a first and second order regression of our the “tall” matrices above. A nice feature of <code class="docutils literal notranslate"><span class="pre">np.linalg.lstsq()</span></code> is that it will calculate SSE. It returns rank and singular values as well, though we won’t usually use these things in this course.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#########################################################################################</span>
<span class="c1"># Performing regression for 1st, 2nd, and 3rd order using numpy.linalg.lstsq()          #</span>
<span class="c1">#########################################################################################</span>

<span class="n">A1np_lsq</span><span class="p">,</span> <span class="n">SSE1</span><span class="p">,</span> <span class="n">rank1</span><span class="p">,</span> <span class="n">sing1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">Y1</span><span class="p">,</span> <span class="n">rcond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">A2np_lsq</span><span class="p">,</span> <span class="n">SSE2</span><span class="p">,</span> <span class="n">rank2</span><span class="p">,</span> <span class="n">sing2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">Y2</span><span class="p">,</span> <span class="n">rcond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">A3np_lsq</span><span class="p">,</span> <span class="n">SSE3</span><span class="p">,</span> <span class="n">rank3</span><span class="p">,</span> <span class="n">sing3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span> <span class="n">Y3</span><span class="p">,</span> <span class="n">rcond</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>

<span class="c1">#########################################################################################</span>
<span class="c1"># Print coefficients; compare matrix method, numpy.polyval(), and numpy.linalg.lstsq()  #</span>
<span class="c1">#########################################################################################</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">A1</span><span class="p">,</span> <span class="n">A1np_poly</span><span class="p">,</span> <span class="n">A1np_lsq</span><span class="p">]),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">A2</span><span class="p">,</span> <span class="n">A2np_poly</span><span class="p">,</span> <span class="n">A2np_lsq</span><span class="p">]),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">A3</span><span class="p">,</span> <span class="n">A3np_poly</span><span class="p">,</span> <span class="n">A3np_lsq</span><span class="p">]),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1">#########################################################################################</span>
<span class="c1"># Print residual sum of squares for 1st, 2nd, and 3rd order fits                        #</span>
<span class="c1"># For a given data set, SSE will decrease as the order of the polynomial increases      #</span>
<span class="c1"># This does not mean that a higher order polynomial is &quot;better&quot; per se                  #</span>
<span class="c1"># But it does mean that a higher order polynomial more closely predicts measured values #</span>
<span class="c1">#########################################################################################</span>

<span class="nb">print</span><span class="p">(</span><span class="n">SSE1</span><span class="p">,</span> <span class="n">SSE2</span><span class="p">,</span> <span class="n">SSE3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[-0.90421001  0.92118569]
 [-0.90421001  0.92118569]
 [-0.90421001  0.92118569]] 

[[-0.69969354 -0.14991027  0.76170812]
 [-0.69969354 -0.14991027  0.76170812]
 [-0.69969354 -0.14991027  0.76170812]] 

[[ 4.85887321 -9.04727267  4.12600401  0.14299066]
 [ 4.85887321 -9.04727267  4.12600401  0.14299066]
 [ 4.85887321 -9.04727267  4.12600401  0.14299066]] 

[0.49163018] [0.47936939] [0.45149249]
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="587-N37.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Interpolation and Regression</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-recap">A Recap</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ancillary-skills">Ancillary Skills</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#python-will-do-all-this-stuff-for-you-if-you-want">Python will do all this stuff for you if you want…</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Jesse Q. Bond, Syracuse University
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>