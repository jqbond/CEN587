{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Regression\n",
    "\n",
    "Relatively advanced problems in optimization...nonlinear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Least Squares Recap:\n",
    "\n",
    "We should have a feel for how useful least squares analysis can be at this point.  We've done this quite a bit using both linear and nonlinear least squares to find rate laws and/or kinetic parameters (rate constants, activation barriers, etc.).\n",
    "\n",
    "The main problem with kinetic analysis is that, although we usually have a single equation that describes the performance of our reactor, like the solution below for a first order reaction in a constant volume batch reactor:\n",
    "\n",
    "$$C_A = C_{A0}e^{-kt}$$\n",
    "\n",
    "We always have 10 or 20 or 50 data points to work with.  That means we would like to satisfy the above equation at all of those data points...but we can't!  Experimental errors mean that there is no unique solution to this problem.  Instead, we have to find the *best* values of the parameters of interest.  In our context, the *best* value is the one that minimizes the total sum of square errors between our measurement and our model's prediction.\n",
    "\n",
    "$$SSE = \\sum_i(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "Knowing how to solve least squares problems is extremely useful.  This is basically how we approach trying to find the \"best\" value of a variable parameter in all sorts of models.  No matter what problem you are trying to solve, the method behind nonlinear least squares is always the same:\n",
    "\n",
    "1. Propose a model that includes your variable parameters (e.g., a rate constant or reaction order)\n",
    "2. Use that model to calculate the value of your measurable quantity at each experimental condition (e.g., a concentration at a specific time)\n",
    "3. Calculate the square error between your measurement and the value predicted by your model\n",
    "4. Sum the square errors for each data point.\n",
    "5. Use an iterative solver to vary the parameters of interest until the sum of square errors is at a minimum.\n",
    "\n",
    "Learn these principles, and learn how to apply them.  You will find them useful in numerous situations.  We'll apply them to kinetic analysis today, but they are extremely, extremely useful!!!\n",
    "\n",
    "```{note}\n",
    "Although Linear regression methods are extremely useful and often preferential, sometimes it is not possible to linearize a problem, so we will use today's recitation to get some extra practice with nonlinear regression today, and we will specifically avoid using linear algebra solutions.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Problem 01\n",
    "\n",
    "We want to determine the rate constant for the following reaction:\n",
    "\n",
    "$$A \\longrightarrow B$$\n",
    "\n",
    "For this experiment, we use a constant volume batch reactor, and we know a few things about the reaction.  First, the rate of reaction is first order in species A.  Second, the rate is independent of the concentration of B. Based on the above, we write the following rate law:\n",
    "\n",
    "$$r = kC_A$$\n",
    "\n",
    "Finally, the concentration of A at the start of the experiment was quantified very precisely.  We know that it is equal to 15 moles per liter.  Then:\n",
    "\n",
    "$$C_{A0} = 15 \\ \\textrm{mol} \\ \\textrm{L}^{-1}$$\n",
    "\n",
    "Otherwise, the only information that we have is that we measured the concentration of the reactant (A) as it disappears over time in the reactor.  The data is compiled in a separate CSV files, t1.csv and C1.csv. We will first review how to import data from these files and convert that data into a numpy array in the cell below.  Times are in minutes, and concentrations are in mol/L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# #Load Experimental Times; convert to 1D numpy array\n",
    "# file = open(\"t1.csv\") #experimental times in minutes\n",
    "# csvreader = csv.reader(file)\n",
    "# rows = []\n",
    "# print(rows)\n",
    "# for row in csvreader:\n",
    "#     rows.append(row)\n",
    "#     # print(rows)\n",
    "# file.close()\n",
    "\n",
    "# np.array(rows)#[0][0]\n",
    "# type(np.array(rows)[0, 0])\n",
    "# print(np.array(rows, dtype = 'float').shape)\n",
    "# t1 = np.array(rows, dtype = 'float').reshape(len(rows), )\n",
    "# print(t1.shape)\n",
    "\n",
    "# #Load Experimental Concentrations; convert to 1D numpy array\n",
    "# file = open(\"C1.csv\")\n",
    "# csvreader = csv.reader(file)\n",
    "# rows = []\n",
    "# for row in csvreader:\n",
    "#      rows.append(row)\n",
    "# file.close()\n",
    "# # print(np.array(rows, dtype = 'float').shape)\n",
    "# C1 = np.array(rows, dtype = 'float').reshape(len(rows), )\n",
    "# # print(C1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot Data\n",
    "# plt.figure(figsize = (5, 5))\n",
    "# plt.scatter(t1, C1, marker = 'o', color = 'none', edgecolor = 'blue', label = 'Experimental CA')\n",
    "# plt.xlabel('time (min)', fontsize = 12)\n",
    "# plt.ylabel('CA (mol/L)', fontsize = 12)\n",
    "# plt.xlim(0, 70)\n",
    "# plt.ylim(0, 16)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Material Balance on the Batch Reactor\n",
    "\n",
    "We know that this is a first order reaction in a constant volume batch reactor.  An appropriate material balance to model this system is:\n",
    "\n",
    "$$\\frac{dC_A}{dt} = -kC_A$$\n",
    "\n",
    "And we know how to solve this analytically to get:\n",
    "\n",
    "$$C_A = C_{A0}\\exp(-kt)$$\n",
    "\n",
    "So we have a nonlinear model.  We can overlay that model with a guess at the rate constant and see how well it agrees with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA0   = 15.0  #mol/L\n",
    "# ktest = 0.01  #1/min\n",
    "# tmod  = np.linspace(0, 70, 100)\n",
    "# CAfun = lambda k,t: CA0*np.exp(-k*t) \n",
    "\n",
    "# plt.figure(figsize = (5, 5))\n",
    "# plt.scatter(t1, C1, marker = 'o', color = 'none', edgecolor = 'blue', label = 'Experimental CA')\n",
    "# plt.plot(tmod, CAfun(ktest, tmod), label = 'Model Pred. for CA', color = 'black', linestyle = 'dashed')\n",
    "# plt.xlabel('time (min)', fontsize = 12)\n",
    "# plt.ylabel('CA (mol/L)', fontsize = 12)\n",
    "# plt.xlim(0, 70)\n",
    "# plt.ylim(0, 16)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an optimization routine\n",
    "\n",
    "As usual, we can do much better by creating an objective function and minimizing it with an optimization routine.  Here, we'll create an objective function that calculates our sum of squares as a function of our variable parameter (the rate constant), and we'll use opt.minimize_scaler to find the \"best\" value of the rate constant, i.e., the one that minimizes the error between our model predictions and our measurments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def obj1(par):\n",
    "#     k     = par \n",
    "#     texp  = t1 \n",
    "#     CAexp = C1 \n",
    "    \n",
    "#     CA0   = 15.0  #mol/L\n",
    "#     CAmod = CAfun(k, texp)  #mol/L\n",
    "    \n",
    "#     SSE = np.sum(((CAexp - CAmod))**2) \n",
    "#     return SSE\n",
    "\n",
    "# ans1  = opt.minimize_scalar(obj1)#, method = 'Brent', bracket = [0.001, 1])\n",
    "# k_opt = ans1.x\n",
    "# SSE   = ans1.fun\n",
    "# print(ans1, '\\n')\n",
    "# print(f'The optimum rate constant is {k_opt:3.3f} 1/min with a SSE value of {SSE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the optimum value of the rate constant, we can overlay the model with our measurments and see how well it does.  It is good to get in the habit of looking at the raw residual error as it gives you an idea of whether your measurements are randomly scattered about the best fit line, or if there is systematic deviation.  We'll calculate that quanity and plot it as a function of each measurement's concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA0   = 15.0  #mol/L\n",
    "# texp  = t1\n",
    "# tmod  = np.linspace(0, max(t1), 100)\n",
    "# CAmod = CAfun(k_opt, tmod) #generate smooth curve showing model prediction as a continuous function of time\n",
    "# resid = CAfun(k_opt, texp) - C1 #generate residual error at each experimental time\n",
    "\n",
    "# #overlay best fit model with measurements\n",
    "\n",
    "# plt.figure(1, figsize = (5, 5))\n",
    "# plt.scatter(t1, C1, marker = 'o', color = 'none', edgecolor = 'blue', label = 'Experimental CA')\n",
    "# plt.plot(tmod, CAmod, label = 'Model Pred. for CA', color = 'black', linestyle = 'dashed')\n",
    "# plt.xlabel('time (min)', fontsize = 12)\n",
    "# plt.ylabel('CA (mol/L)', fontsize = 12)\n",
    "# plt.xlim(0, 70)\n",
    "# plt.ylim(0, 16)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# #plot residual errors\n",
    "# plt.figure(2, figsize = (5, 5))\n",
    "# plt.scatter(C1, resid, marker = 's', color = 'none', edgecolor = 'red', label = 'Experimental CA')\n",
    "# plt.hlines(0, 0, 20, color = 'black', linestyle = 'dashed', label = 'Zero error')\n",
    "# plt.xlim(0, 20)\n",
    "# plt.ylim(-1, 1)\n",
    "# plt.xlabel('Concentration (mol/L)', fontsize = 12)\n",
    "# plt.ylabel('residual error', fontsize = 12)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Problem 02\n",
    "\n",
    "The two following reactions occur in a constant volume batch reactor:\n",
    "\n",
    "\\begin{align}\n",
    "    2A + B \\longrightarrow C \\\\\n",
    "    B  + 2C \\longrightarrow D \\\\\n",
    "\\end{align}\n",
    "\n",
    "Both reactions follow an elementary rate law; however, we do not know either of the rate constants (k$_1$ and k$_2$), so we attempt to estimate them from data collected in our constant volume batch reactor.  The data (time in minutes and concentrations of A, B, C, and D in moles per liter) are included in the CSV files t2.csv and C2.csv\n",
    "\n",
    "The initial concentrations of species A and B are 25 and 20 moles per liter, respectively.  The initial concentrations of C and D are both zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load Experimental Times; convert to 1D numpy array\n",
    "# file = open(\"t2.csv\")\n",
    "# csvreader = csv.reader(file)\n",
    "# rows = []\n",
    "# for row in csvreader:\n",
    "#      rows.append(row)\n",
    "# file.close()\n",
    "# t2 = np.array(rows, dtype = 'float').reshape(len(rows),)\n",
    "\n",
    "# #Load Experimental Concentrations; convert to 1D numpy array\n",
    "# file = open(\"C2.csv\")\n",
    "# csvreader = csv.reader(file)\n",
    "# rows = []\n",
    "# for row in csvreader:\n",
    "#      rows.append(row)\n",
    "# file.close()\n",
    "# C2 = np.array(rows, dtype = 'float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot the data to get a feel for what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (5, 5))\n",
    "# plt.plot(t2, C2, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# plt.xlabel('time (min)', fontsize = 12)\n",
    "# plt.ylabel('Concentration (mol/L)', fontsize = 12)\n",
    "# plt.xlim(0, 70)\n",
    "# plt.ylim(0, 30)\n",
    "# plt.legend(['CA', 'CB', 'CC', 'CD'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Least Squares Problem\n",
    "\n",
    "When we move toward the least squares analysis, we run into an issue: we can't solve this reactor model analytically as we would with a normal \"integral analysis\" method.  We have to integrate it numerically.  This gets a little more tricky in terms of the code.  First, let's just remember how we would solve this problem in general by solving a constant volume batch reactor for values of k1 and k2 that we will just guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def P2a(t, var):\n",
    "#     CA = var[0]\n",
    "#     CB = var[1]\n",
    "#     CC = var[2]\n",
    "#     CD = var[3]\n",
    "    \n",
    "#     k1 = 0.05\n",
    "#     k2 = 0.05\n",
    "    \n",
    "#     r1 = k1*CA**2*CB\n",
    "#     r2 = k2*CB*CC**2\n",
    "    \n",
    "#     RA = -2*r1\n",
    "#     RB = -1*r1 - 1*r2\n",
    "#     RC =  1*r1 - 2*r2\n",
    "#     RD =  0*r1 + 1*r2\n",
    "    \n",
    "#     D1 = RA\n",
    "#     D2 = RB\n",
    "#     D3 = RC\n",
    "#     D4 = RD\n",
    "#     return [D1, D2, D3, D4]\n",
    "\n",
    "# C0     = [25, 20, 0, 0] #mol/L\n",
    "# tspan  = (0, max(t2))\n",
    "# ans2a  = solve_ivp(P2a, tspan, C0, atol = 1e-8, rtol = 1e-8)\n",
    "\n",
    "# plt.figure(figsize = (5, 5))\n",
    "# plt.plot(t2, C2, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# plt.plot(ans2a.t, ans2a.y.T, color = 'black', linestyle = 'dashed', linewidth = 1)\n",
    "# #plt.semilogx(t2, C2, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# #plt.semilogx(ans2a.t, ans2a.y.T, color = 'black', linestyle = 'dashed', linewidth = 1)\n",
    "# plt.xlabel('time (min)', fontsize = 12)\n",
    "# plt.ylabel('Concentration (mol/L)', fontsize = 12)\n",
    "# plt.xlim(0, 70)\n",
    "# plt.ylim(0, 30)\n",
    "# plt.legend(['CA', 'CB', 'CC', 'CD'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a more flexible ODE function that allows us to pass parameters\n",
    "\n",
    "But we have to be thinking more flexibly.  We need to not be setting the rate constants ourselves, but allowing an optimization routine to iteratively vary them.  We'll work through this in a couple of steps.  First, let's convert our ODE system for the batch reactor so that it will accept parameters as arguments; this will make it much easier for us to set their values to try new combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def P2b(t, var, par):\n",
    "#     CA = var[0]\n",
    "#     CB = var[1]\n",
    "#     CC = var[2]\n",
    "#     CD = var[3]\n",
    "    \n",
    "#     k1 = par[0]\n",
    "#     k2 = par[1]\n",
    "    \n",
    "#     r1 = k1*CA**2*CB\n",
    "#     r2 = k2*CB*CC**2\n",
    "    \n",
    "#     RA = -2*r1\n",
    "#     RB = -1*r1 - 1*r2\n",
    "#     RC =  1*r1 - 2*r2\n",
    "#     RD =  0*r1 + 1*r2\n",
    "    \n",
    "#     D1 = RA\n",
    "#     D2 = RB\n",
    "#     D3 = RC\n",
    "#     D4 = RD\n",
    "#     return [D1, D2, D3, D4]\n",
    "\n",
    "# C0     = [25, 20, 0, 0] #mol/L\n",
    "# tspan  = (0, max(t2))\n",
    "# par    = [1, 1]\n",
    "# ans2b  = solve_ivp(P2b, tspan, C0, args = (par, ), atol = 1e-8, rtol = 1e-8)\n",
    "\n",
    "# plt.figure(figsize = (5, 5))\n",
    "# plt.plot(t2, C2, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# plt.plot(ans2b.t, ans2b.y.T, color = 'black', linestyle = 'dashed', linewidth = 1)\n",
    "# # plt.semilogx(t2, C2, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# # plt.semilogx(ans2b.t, ans2b.y.T, color = 'black', linestyle = 'dashed', linewidth = 1)\n",
    "# plt.xlabel('time (min)')\n",
    "# plt.ylabel('Concentration (mol/L)')\n",
    "# plt.xlim(0, 70)\n",
    "# plt.ylim(0, 30)\n",
    "# plt.legend(['CA', 'CB', 'CC', 'CD'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the ODE solver to evaluate your objective function\n",
    "\n",
    "Now, we can use that model along with the ODE solver to calculate the residual sum of squares between the model and measurments.  We'll do this first as a demo, and then we'll convert it into an objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texp   = t2\n",
    "# Cexp   = C2\n",
    "# C0     = [25, 20, 0, 0] #mol/L\n",
    "# tspan  = (0, max(t2))\n",
    "\n",
    "# par0    = [0.05, 0.05]\n",
    "# ans2c   = solve_ivp(P2b, tspan, C0, args = (par0, ), atol = 1e-8, rtol = 1e-8)#, t_eval = texp)\n",
    "# Cmod    = ans2c.y.T\n",
    "\n",
    "# print(Cexp)\n",
    "# print(Cmod)\n",
    "# SQERROR = ((Cexp - Cmod))**2\n",
    "# print(Cexp.shape)\n",
    "# print(Cmod.shape)\n",
    "# print(SQERROR)\n",
    "# print(SQERROR.shape)\n",
    "# print(SQERROR.flatten())\n",
    "# print(SQERROR.flatten().shape)\n",
    "# SSE     = np.sum(SQERROR.flatten())\n",
    "# print(SSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an understanding of how we could use a numerical solution to generate model predictions at various experimental times, we can embed this in an objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def obj2(par):\n",
    "#     texp   = t2\n",
    "#     Cexp   = C2\n",
    "#     C0     = [25, 20, 0, 0] #mol/L\n",
    "#     tspan  = (0, max(t2))\n",
    "\n",
    "#     ans2    = solve_ivp(P2b, tspan, C0, args = (par, ), atol = 1e-8, rtol = 1e-8, t_eval = texp)\n",
    "#     Cmod    = ans2.y.T\n",
    "    \n",
    "#     SQERROR = ((Cexp - Cmod))**2 \n",
    "#     SSE     = np.sum(SQERROR.flatten())\n",
    "#     print(f'For k1 = {par[0]:8.2E} and k2 = {par[1]:8.2E}, SSE = {SSE:8.2E}')\n",
    "#     return SSE\n",
    "\n",
    "# par0  = [0.05, 0.05]\n",
    "# ans2d = opt.minimize(obj2, par0)\n",
    "    \n",
    "# bnds  = ((0, None), (0, None))\n",
    "# ans2d = opt.minimize(obj2, par0, method = 'L-BFGS-B', bounds = bnds)\n",
    "# print(ans2d, '\\n')\n",
    "# k1_opt, k2_opt = ans2d.x\n",
    "# par_opt = ans2d.x\n",
    "# SSE   = ans2d.fun\n",
    "# print(f'The optimum rates constant are k1 = {k1_opt:3.3E} and k2 = {k2_opt:3.3E} giving an SSE value of {SSE:3.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans2e  = solve_ivp(P2b, tspan, C0, args = (par_opt, ), atol = 1e-8, rtol = 1e-8, t_eval = t2)\n",
    "# print(C2)\n",
    "# print(C2.shape)\n",
    "# print(ans2e.y)\n",
    "# print(ans2e.y.shape)\n",
    "# print(ans2e.y.T)\n",
    "# print(ans2e.y.T.shape)\n",
    "# resid  = (C2 - ans2e.y.T)\n",
    "# nexp   = len(t2)\n",
    "# expn   = np.linspace(0, nexp, nexp)\n",
    "\n",
    "# plt.figure(figsize = (5, 5))\n",
    "# plt.plot(t2, C2, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# plt.plot(ans2e.t, ans2e.y.T, color = 'black', linestyle = 'dashed', linewidth = 1)\n",
    "# #plt.semilogx(t2, C2, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# #plt.semilogx(ans2e.t, ans2e.y.T, color = 'black', linestyle = 'dashed', linewidth = 1)\n",
    "# plt.xlabel('time (min)')\n",
    "# plt.ylabel('Concentration (mol/L)')\n",
    "# plt.xlim(0, 70)\n",
    "# plt.ylim(0, 30)\n",
    "# plt.legend(['CA', 'CB', 'CC', 'CD'])\n",
    "\n",
    "# plt.figure(figsize = (5, 5))\n",
    "# plt.plot(expn, resid, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# plt.xlabel('Measurement Number')\n",
    "# plt.ylabel('residual error')\n",
    "# plt.legend(['error in CA', 'error in CB', 'error in CC', 'error in CD'], loc = 'lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parity = [1e-7, 30]\n",
    "# plt.plot(C2, ans2e.y.T, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# plt.plot(parity, parity, color = 'black', linestyle = 'dashed', linewidth = 1)\n",
    "# #plt.loglog(C2, ans2e.y.T, marker = 'o', markerfacecolor = 'none', linestyle = 'none')\n",
    "# #plt.loglog(parity, parity, color = 'black', linestyle = 'dashed', linewidth = 1)\n",
    "# plt.xlabel('experimental measurements', fontsize = 12)\n",
    "# plt.ylabel('model predictions', fontsize = 12)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
